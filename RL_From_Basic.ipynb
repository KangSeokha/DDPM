{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyheSC4inyzjIW6/HuROLc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangSeokha/DDPM/blob/main/RL_From_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH5 MCLearning"
      ],
      "metadata": {
        "id": "x-d_hV7oottA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_right(self):\n",
        "        self.y += 1\n",
        "        if self.y > 3:\n",
        "            self.y = 3\n",
        "\n",
        "    def move_left(self):\n",
        "        self.y -= 1\n",
        "        if self.y < 0:\n",
        "            self.y = 0\n",
        "\n",
        "    def move_up(self):\n",
        "        self.x -= 1\n",
        "        if self.x < 0:\n",
        "            self.x = 0\n",
        "\n",
        "    def move_down(self):\n",
        "        self.x += 1\n",
        "        if self.x > 3:\n",
        "            self.x = 3\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x == 3 and self.y == 3:\n",
        "            return True\n",
        "        else :\n",
        "            return False\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.x, self.y)\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select_action(self):\n",
        "        coin = random.random()\n",
        "        if coin < 0.25:\n",
        "            action = 0\n",
        "        elif coin < 0.5:\n",
        "            action = 1\n",
        "        elif coin < 0.75:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 3\n",
        "        return action\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = Agent()\n",
        "    data = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    gamma = 1.0\n",
        "    reward = -1\n",
        "    alpha = 0.001\n",
        "\n",
        "    for k in range(50000):\n",
        "        done = False\n",
        "        history = []\n",
        "\n",
        "        while not done:\n",
        "            action = agent.select_action()\n",
        "            (x,y), reward, done = env.step(action)\n",
        "            history.append((x,y,reward))\n",
        "        env.reset()\n",
        "\n",
        "        cum_reward = 0\n",
        "        for transition in history[::-1]:\n",
        "            x, y, reward = transition\n",
        "            data[x][y] = data[x][y] + alpha*(cum_reward-data[x][y])\n",
        "            cum_reward = reward + gamma*cum_reward  # 책에 오타가 있어 수정하였습니다\n",
        "\n",
        "    for row in data:\n",
        "        print(row)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjol4lQAouZ8",
        "outputId": "b46936a8-00c2-4658-e206-1550806ac303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-58.820001613934416, -57.07861740280086, -51.399828193102046, -49.70203520800069]\n",
            "[-57.27679042949309, -53.237622808419, -46.13648217439738, -40.309660909678776]\n",
            "[-55.216717086501276, -48.57105422415603, -38.16426576494489, -26.951208969342204]\n",
            "[-54.48645637066313, -45.55604512841754, -28.36910856418912, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH5 TD Learning"
      ],
      "metadata": {
        "id": "K4UZ3B0VozOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_right(self):\n",
        "        self.y += 1\n",
        "        if self.y > 3:\n",
        "            self.y = 3\n",
        "\n",
        "    def move_left(self):\n",
        "        self.y -= 1\n",
        "        if self.y < 0:\n",
        "            self.y = 0\n",
        "\n",
        "    def move_up(self):\n",
        "        self.x -= 1\n",
        "        if self.x < 0:\n",
        "            self.x = 0\n",
        "\n",
        "    def move_down(self):\n",
        "        self.x += 1\n",
        "        if self.x > 3:\n",
        "            self.x = 3\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x == 3 and self.y == 3:\n",
        "            return True\n",
        "        else :\n",
        "            return False\n",
        "\n",
        "    def get_state(self):\n",
        "        return (self.x, self.y)\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select_action(self):\n",
        "        coin = random.random()\n",
        "        if coin < 0.25:\n",
        "            action = 0\n",
        "        elif coin < 0.5:\n",
        "            action = 1\n",
        "        elif coin < 0.75:\n",
        "            action = 2\n",
        "        else:\n",
        "            action = 3\n",
        "        return action\n",
        "\n",
        "\n",
        "def main():\n",
        "    #TD\n",
        "    env = GridWorld()\n",
        "    agent = Agent()\n",
        "    data = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    gamma = 1.0\n",
        "    reward = -1\n",
        "    alpha = 0.01\n",
        "\n",
        "    for k in range(50000):\n",
        "        done = False\n",
        "        while not done:\n",
        "            x, y = env.get_state()\n",
        "            action = agent.select_action()\n",
        "            (x_prime, y_prime), reward, done = env.step(action)\n",
        "            x_prime, y_prime = env.get_state()\n",
        "            data[x][y] = data[x][y] + alpha*(reward+gamma*data[x_prime][y_prime]-data[x][y])\n",
        "        env.reset()\n",
        "\n",
        "    for row in data:\n",
        "        print(row)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NadKnww_ozIn",
        "outputId": "c8e6e9a7-f790-4bcc-8c0a-1dbfa580ed75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-59.595650566762544, -57.58225513271604, -54.3183835237772, -52.13358805795074]\n",
            "[-57.76226647930214, -54.96324723349311, -50.63055740672823, -46.56402453174607]\n",
            "[-54.441253105072164, -50.309955354996504, -42.38629890522122, -29.427410151380453]\n",
            "[-51.897474812160034, -47.12607572187338, -33.477453064796855, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH6 MC Control"
      ],
      "metadata": {
        "id": "-TTCJf1sozCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1  # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y==0:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==5 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        else:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y==1 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        elif self.y==6:\n",
        "            pass\n",
        "        else:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x==0:\n",
        "            pass\n",
        "        elif self.x==3 and self.y==2:\n",
        "            pass\n",
        "        else:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x==4:\n",
        "            pass\n",
        "        elif self.x==1 and self.y==4:\n",
        "            pass\n",
        "        else:\n",
        "            self.x+=1\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class QAgent():\n",
        "    def __init__(self):\n",
        "        self.q_table = np.zeros((5, 7, 4)) # q벨류를 저장하는 변수. 모두 0으로 초기화.\n",
        "        self.eps = 0.9\n",
        "        self.alpha = 0.01\n",
        "\n",
        "    def select_action(self, s):\n",
        "        # eps-greedy로 액션을 선택\n",
        "        x, y = s\n",
        "        coin = random.random()\n",
        "        if coin < self.eps:\n",
        "            action = random.randint(0,3)\n",
        "        else:\n",
        "            action_val = self.q_table[x,y,:]\n",
        "            action = np.argmax(action_val)\n",
        "        return action\n",
        "\n",
        "    def update_table(self, history):\n",
        "        # 한 에피소드에 해당하는 history를 입력으로 받아 q 테이블의 값을 업데이트 한다\n",
        "        cum_reward = 0\n",
        "        for transition in history[::-1]:\n",
        "            s, a, r, s_prime = transition\n",
        "            x,y = s\n",
        "            # 몬테 카를로 방식을 이용하여 업데이트.\n",
        "            self.q_table[x,y,a] = self.q_table[x,y,a] + self.alpha * (cum_reward - self.q_table[x,y,a])\n",
        "            cum_reward = cum_reward + r\n",
        "\n",
        "    def anneal_eps(self):\n",
        "        self.eps -= 0.03\n",
        "        self.eps = max(self.eps, 0.1)\n",
        "\n",
        "    def show_table(self):\n",
        "        # 학습이 각 위치에서 어느 액션의 q 값이 가장 높았는지 보여주는 함수\n",
        "        q_lst = self.q_table.tolist()\n",
        "        data = np.zeros((5,7))\n",
        "        for row_idx in range(len(q_lst)):\n",
        "            row = q_lst[row_idx]\n",
        "            for col_idx in range(len(row)):\n",
        "                col = row[col_idx]\n",
        "                action = np.argmax(col)\n",
        "                data[row_idx, col_idx] = action\n",
        "        print(data)\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = QAgent()\n",
        "\n",
        "    for n_epi in range(1000): # 총 1,000 에피소드 동안 학습\n",
        "        done = False\n",
        "        history = []\n",
        "\n",
        "        s = env.reset()\n",
        "        while not done: # 한 에피소드가 끝날 때 까지\n",
        "            a = agent.select_action(s)\n",
        "            s_prime, r, done = env.step(a)\n",
        "            history.append((s, a, r, s_prime))\n",
        "            s = s_prime\n",
        "        agent.update_table(history) # 히스토리를 이용하여 에이전트를 업데이트\n",
        "        agent.anneal_eps()\n",
        "\n",
        "    agent.show_table() # 학습이 끝난 결과를 출력\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-a79DqVoy8h",
        "outputId": "69ef2540-406b-402b-be96-aeee8d2f91bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3. 0. 2. 2. 2. 3.]\n",
            " [2. 3. 0. 1. 2. 3. 3.]\n",
            " [3. 3. 0. 1. 0. 3. 0.]\n",
            " [3. 3. 3. 1. 0. 3. 3.]\n",
            " [2. 2. 2. 1. 0. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH6 QLearning"
      ],
      "metadata": {
        "id": "1BrC0EvCoy1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1 # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y==0:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==5 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        else:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y==1 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        elif self.y==6:\n",
        "            pass\n",
        "        else:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x==0:\n",
        "            pass\n",
        "        elif self.x==3 and self.y==2:\n",
        "            pass\n",
        "        else:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x==4:\n",
        "            pass\n",
        "        elif self.x==1 and self.y==4:\n",
        "            pass\n",
        "        else:\n",
        "            self.x+=1\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x==4 and self.y==6:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class QAgent():\n",
        "    def __init__(self):\n",
        "        self.q_table = np.zeros((5, 7, 4)) # 마찬가지로 Q 테이블을 0으로 초기화\n",
        "        self.eps = 0.9\n",
        "\n",
        "    def select_action(self, s):\n",
        "        # eps-greedy로 액션을 선택해준다\n",
        "        x, y = s\n",
        "        coin = random.random()\n",
        "        if coin < self.eps:\n",
        "            action = random.randint(0,3)\n",
        "        else:\n",
        "            action_val = self.q_table[x,y,:]\n",
        "            action = np.argmax(action_val)\n",
        "        return action\n",
        "\n",
        "    def update_table(self, transition):\n",
        "        s, a, r, s_prime = transition\n",
        "        x,y = s\n",
        "        next_x, next_y = s_prime\n",
        "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
        "        # Q러닝 업데이트 식을 이용\n",
        "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + np.amax(self.q_table[next_x,next_y,:]) - self.q_table[x,y,a])\n",
        "\n",
        "    def anneal_eps(self):\n",
        "        self.eps -= 0.01  # Q러닝에선 epsilon 이 좀더 천천히 줄어 들도록 함.\n",
        "        self.eps = max(self.eps, 0.2)\n",
        "\n",
        "    def show_table(self):\n",
        "        q_lst = self.q_table.tolist()\n",
        "        data = np.zeros((5,7))\n",
        "        for row_idx in range(len(q_lst)):\n",
        "            row = q_lst[row_idx]\n",
        "            for col_idx in range(len(row)):\n",
        "                col = row[col_idx]\n",
        "                action = np.argmax(col)\n",
        "                data[row_idx, col_idx] = action\n",
        "        print(data)\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = QAgent()\n",
        "\n",
        "    for n_epi in range(1000):\n",
        "        done = False\n",
        "\n",
        "        s = env.reset()\n",
        "        while not done:\n",
        "            a = agent.select_action(s)\n",
        "            s_prime, r, done = env.step(a)\n",
        "            agent.update_table((s,a,r,s_prime))\n",
        "            s = s_prime\n",
        "        agent.anneal_eps()\n",
        "\n",
        "    agent.show_table()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t76giceCoysb",
        "outputId": "d0e301c5-d67e-459e-b99f-78270f71583d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3. 3. 0. 0. 3. 2. 3.]\n",
            " [3. 3. 0. 2. 2. 3. 3.]\n",
            " [2. 3. 0. 1. 0. 3. 3.]\n",
            " [2. 2. 2. 1. 0. 3. 3.]\n",
            " [1. 1. 2. 1. 0. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH6 SARSA"
      ],
      "metadata": {
        "id": "-OIrb1HHowRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class GridWorld():\n",
        "    def __init__(self):\n",
        "        self.x=0\n",
        "        self.y=0\n",
        "\n",
        "    def step(self, a):\n",
        "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
        "        if a==0:\n",
        "            self.move_left()\n",
        "        elif a==1:\n",
        "            self.move_up()\n",
        "        elif a==2:\n",
        "            self.move_right()\n",
        "        elif a==3:\n",
        "            self.move_down()\n",
        "\n",
        "        reward = -1  # 보상은 항상 -1로 고정\n",
        "        done = self.is_done()\n",
        "        return (self.x, self.y), reward, done\n",
        "\n",
        "    def move_left(self):\n",
        "        if self.y==0:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==5 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        else:\n",
        "            self.y -= 1\n",
        "\n",
        "    def move_right(self):\n",
        "        if self.y==1 and self.x in [0,1,2]:\n",
        "            pass\n",
        "        elif self.y==3 and self.x in [2,3,4]:\n",
        "            pass\n",
        "        elif self.y==6:\n",
        "            pass\n",
        "        else:\n",
        "            self.y += 1\n",
        "\n",
        "    def move_up(self):\n",
        "        if self.x==0:\n",
        "            pass\n",
        "        elif self.x==3 and self.y==2:\n",
        "            pass\n",
        "        else:\n",
        "            self.x -= 1\n",
        "\n",
        "    def move_down(self):\n",
        "        if self.x==4:\n",
        "            pass\n",
        "        elif self.x==1 and self.y==4:\n",
        "            pass\n",
        "        else:\n",
        "            self.x+=1\n",
        "\n",
        "    def is_done(self):\n",
        "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        self.x = 0\n",
        "        self.y = 0\n",
        "        return (self.x, self.y)\n",
        "\n",
        "class QAgent():\n",
        "    def __init__(self):\n",
        "        self.q_table = np.zeros((5, 7, 4)) # 마찬가지로 Q 테이블을 0으로 초기화\n",
        "        self.eps = 0.9\n",
        "\n",
        "    def select_action(self, s):\n",
        "        # eps-greedy로 액션을 선택해준다\n",
        "        x, y = s\n",
        "        coin = random.random()\n",
        "        if coin < self.eps:\n",
        "            action = random.randint(0,3)\n",
        "        else:\n",
        "            action_val = self.q_table[x,y,:]\n",
        "            action = np.argmax(action_val)\n",
        "        return action\n",
        "\n",
        "    def update_table(self, transition):\n",
        "        s, a, r, s_prime = transition\n",
        "        x,y = s\n",
        "        next_x, next_y = s_prime\n",
        "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
        "        # SARSA 업데이트 식을 이용\n",
        "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + self.q_table[next_x,next_y,a_prime] - self.q_table[x,y,a])\n",
        "\n",
        "    def anneal_eps(self):\n",
        "        self.eps -= 0.03\n",
        "        self.eps = max(self.eps, 0.1)\n",
        "\n",
        "    def show_table(self):\n",
        "        q_lst = self.q_table.tolist()\n",
        "        data = np.zeros((5,7))\n",
        "        for row_idx in range(len(q_lst)):\n",
        "            row = q_lst[row_idx]\n",
        "            for col_idx in range(len(row)):\n",
        "                col = row[col_idx]\n",
        "                action = np.argmax(col)\n",
        "                data[row_idx, col_idx] = action\n",
        "        print(data)\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = GridWorld()\n",
        "    agent = QAgent()\n",
        "\n",
        "    for n_epi in range(1000):\n",
        "        done = False\n",
        "\n",
        "        s = env.reset()\n",
        "        while not done:\n",
        "            a = agent.select_action(s)\n",
        "            s_prime, r, done = env.step(a)\n",
        "            agent.update_table((s,a,r,s_prime))\n",
        "            s = s_prime\n",
        "        agent.anneal_eps()\n",
        "\n",
        "    agent.show_table()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm-7dzwAowG5",
        "outputId": "e328aa4f-f507-4464-fc16-80ce6d8e37bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3. 0. 0. 3. 2. 3.]\n",
            " [2. 3. 0. 2. 2. 3. 3.]\n",
            " [2. 3. 0. 1. 0. 2. 3.]\n",
            " [2. 2. 2. 1. 0. 3. 3.]\n",
            " [3. 3. 2. 1. 0. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo-rxJHjjvzK"
      },
      "outputs": [],
      "source": [
        "#CH7 Cosine Fitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "def true_fun(X):\n",
        "    noise = np.random.rand(X.shape[0]) * 0.4 - 0.2\n",
        "    return np.cos(1.5 * np.pi * X) + X + noise\n",
        "\n",
        "def plot_results(model):\n",
        "    x = np.linspace(0, 5, 100)\n",
        "    input_x = torch.from_numpy(x).float().unsqueeze(1)\n",
        "    print(\"input_x: \", input_x)\n",
        "    plt.plot(x, true_fun(x), label=\"Truth\")\n",
        "    plt.plot(x, model(input_x).detach().numpy(), label=\"Prediction\")\n",
        "    plt.legend(loc='lower right',fontsize=15)\n",
        "    plt.xlim((0, 5))\n",
        "    plt.ylim((-1, 5))\n",
        "    plt.grid()\n",
        "\n",
        "def main():\n",
        "    data_x = np.random.rand(10000) * 5 # 0~5 사이 숫자 1만개를 샘플링하여 인풋으로 사용\n",
        "    model = Model()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for step in range(10000):\n",
        "        batch_x = np.random.choice(data_x, 32) # 랜덤하게 뽑힌 32개의 데이터로 mini-batch를 구성\n",
        "        batch_x_tensor = torch.from_numpy(batch_x).float().unsqueeze(1)\n",
        "        pred = model(batch_x_tensor)\n",
        "\n",
        "        batch_y = true_fun(batch_x)\n",
        "        truth = torch.from_numpy(batch_y).float().unsqueeze(1)\n",
        "        loss = F.mse_loss(pred, truth) # 손실 함수인 MSE를 계산하는 부분\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.mean().backward() # 역전파를 통한 그라디언트 계산이 일어나는 부분\n",
        "        optimizer.step() # 실제로 파라미터를 업데이트 하는 부분\n",
        "\n",
        "    plot_results(model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6PP2LbXQkNPa",
        "outputId": "221ae767-9a84-40c1-bdf9-61ce45de44a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_x:  tensor([[0.0000],\n",
            "        [0.0505],\n",
            "        [0.1010],\n",
            "        [0.1515],\n",
            "        [0.2020],\n",
            "        [0.2525],\n",
            "        [0.3030],\n",
            "        [0.3535],\n",
            "        [0.4040],\n",
            "        [0.4545],\n",
            "        [0.5051],\n",
            "        [0.5556],\n",
            "        [0.6061],\n",
            "        [0.6566],\n",
            "        [0.7071],\n",
            "        [0.7576],\n",
            "        [0.8081],\n",
            "        [0.8586],\n",
            "        [0.9091],\n",
            "        [0.9596],\n",
            "        [1.0101],\n",
            "        [1.0606],\n",
            "        [1.1111],\n",
            "        [1.1616],\n",
            "        [1.2121],\n",
            "        [1.2626],\n",
            "        [1.3131],\n",
            "        [1.3636],\n",
            "        [1.4141],\n",
            "        [1.4646],\n",
            "        [1.5152],\n",
            "        [1.5657],\n",
            "        [1.6162],\n",
            "        [1.6667],\n",
            "        [1.7172],\n",
            "        [1.7677],\n",
            "        [1.8182],\n",
            "        [1.8687],\n",
            "        [1.9192],\n",
            "        [1.9697],\n",
            "        [2.0202],\n",
            "        [2.0707],\n",
            "        [2.1212],\n",
            "        [2.1717],\n",
            "        [2.2222],\n",
            "        [2.2727],\n",
            "        [2.3232],\n",
            "        [2.3737],\n",
            "        [2.4242],\n",
            "        [2.4747],\n",
            "        [2.5253],\n",
            "        [2.5758],\n",
            "        [2.6263],\n",
            "        [2.6768],\n",
            "        [2.7273],\n",
            "        [2.7778],\n",
            "        [2.8283],\n",
            "        [2.8788],\n",
            "        [2.9293],\n",
            "        [2.9798],\n",
            "        [3.0303],\n",
            "        [3.0808],\n",
            "        [3.1313],\n",
            "        [3.1818],\n",
            "        [3.2323],\n",
            "        [3.2828],\n",
            "        [3.3333],\n",
            "        [3.3838],\n",
            "        [3.4343],\n",
            "        [3.4848],\n",
            "        [3.5354],\n",
            "        [3.5859],\n",
            "        [3.6364],\n",
            "        [3.6869],\n",
            "        [3.7374],\n",
            "        [3.7879],\n",
            "        [3.8384],\n",
            "        [3.8889],\n",
            "        [3.9394],\n",
            "        [3.9899],\n",
            "        [4.0404],\n",
            "        [4.0909],\n",
            "        [4.1414],\n",
            "        [4.1919],\n",
            "        [4.2424],\n",
            "        [4.2929],\n",
            "        [4.3434],\n",
            "        [4.3939],\n",
            "        [4.4444],\n",
            "        [4.4949],\n",
            "        [4.5455],\n",
            "        [4.5960],\n",
            "        [4.6465],\n",
            "        [4.6970],\n",
            "        [4.7475],\n",
            "        [4.7980],\n",
            "        [4.8485],\n",
            "        [4.8990],\n",
            "        [4.9495],\n",
            "        [5.0000]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH8 DQN"
      ],
      "metadata": {
        "id": "csR7AS-alq5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import collections\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "gamma         = 0.98\n",
        "buffer_limit  = 50000\n",
        "batch_size    = 32\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "\n",
        "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class Qnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Qnet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            return random.randint(0,1)\n",
        "        else :\n",
        "            return out.argmax().item()\n",
        "\n",
        "def train(q, q_target, memory, optimizer):\n",
        "    for i in range(10):\n",
        "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1,a)\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    q = Qnet()\n",
        "    q_target = Qnet()\n",
        "    q_target.load_state_dict(q.state_dict())\n",
        "    memory = ReplayBuffer()\n",
        "\n",
        "    print_interval = 20\n",
        "    score = 0.0\n",
        "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            a = q.sample_action(torch.from_numpy(s).float(), epsilon)\n",
        "            s_prime, r, done, info = env.step(a)\n",
        "            done_mask = 0.0 if done else 1.0\n",
        "            memory.put((s,a,r/100.0,s_prime, done_mask))\n",
        "            s = s_prime\n",
        "\n",
        "            score += r\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if memory.size()>2000:\n",
        "            train(q, q_target, memory, optimizer)\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            q_target.load_state_dict(q.state_dict())\n",
        "            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
        "                                                            n_epi, score/print_interval, memory.size(), epsilon*100))\n",
        "            score = 0.0\n",
        "    env.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J_vX0dzBlfEb",
        "outputId": "8e3ddc73-3368-4ebd-9113-1e5a918e58f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_episode :20, score : 9.9, n_buffer : 199, eps : 7.9%\n",
            "n_episode :40, score : 9.6, n_buffer : 391, eps : 7.8%\n",
            "n_episode :60, score : 9.4, n_buffer : 579, eps : 7.7%\n",
            "n_episode :80, score : 9.8, n_buffer : 774, eps : 7.6%\n",
            "n_episode :100, score : 10.1, n_buffer : 976, eps : 7.5%\n",
            "n_episode :120, score : 9.6, n_buffer : 1167, eps : 7.4%\n",
            "n_episode :140, score : 9.7, n_buffer : 1360, eps : 7.3%\n",
            "n_episode :160, score : 9.8, n_buffer : 1556, eps : 7.2%\n",
            "n_episode :180, score : 9.6, n_buffer : 1747, eps : 7.1%\n",
            "n_episode :200, score : 9.9, n_buffer : 1945, eps : 7.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-871dc58d492f>:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_episode :220, score : 13.2, n_buffer : 2210, eps : 6.9%\n",
            "n_episode :240, score : 10.4, n_buffer : 2419, eps : 6.8%\n",
            "n_episode :260, score : 9.8, n_buffer : 2614, eps : 6.7%\n",
            "n_episode :280, score : 9.9, n_buffer : 2813, eps : 6.6%\n",
            "n_episode :300, score : 11.3, n_buffer : 3040, eps : 6.5%\n",
            "n_episode :320, score : 14.7, n_buffer : 3333, eps : 6.4%\n",
            "n_episode :340, score : 46.6, n_buffer : 4265, eps : 6.3%\n",
            "n_episode :360, score : 99.5, n_buffer : 6254, eps : 6.2%\n",
            "n_episode :380, score : 177.2, n_buffer : 9798, eps : 6.1%\n",
            "n_episode :400, score : 202.9, n_buffer : 13857, eps : 6.0%\n",
            "n_episode :420, score : 226.7, n_buffer : 18390, eps : 5.9%\n",
            "n_episode :440, score : 225.8, n_buffer : 22906, eps : 5.8%\n",
            "n_episode :460, score : 202.7, n_buffer : 26960, eps : 5.7%\n",
            "n_episode :480, score : 125.2, n_buffer : 29463, eps : 5.6%\n",
            "n_episode :500, score : 196.3, n_buffer : 33390, eps : 5.5%\n",
            "n_episode :520, score : 135.8, n_buffer : 36105, eps : 5.4%\n",
            "n_episode :540, score : 272.1, n_buffer : 41546, eps : 5.3%\n",
            "n_episode :560, score : 250.9, n_buffer : 46564, eps : 5.2%\n",
            "n_episode :580, score : 253.2, n_buffer : 50000, eps : 5.1%\n",
            "n_episode :600, score : 245.5, n_buffer : 50000, eps : 5.0%\n",
            "n_episode :620, score : 220.8, n_buffer : 50000, eps : 4.9%\n",
            "n_episode :640, score : 192.9, n_buffer : 50000, eps : 4.8%\n",
            "n_episode :660, score : 157.4, n_buffer : 50000, eps : 4.7%\n",
            "n_episode :680, score : 157.9, n_buffer : 50000, eps : 4.6%\n",
            "n_episode :700, score : 175.2, n_buffer : 50000, eps : 4.5%\n",
            "n_episode :720, score : 193.4, n_buffer : 50000, eps : 4.4%\n",
            "n_episode :740, score : 195.2, n_buffer : 50000, eps : 4.3%\n",
            "n_episode :760, score : 183.7, n_buffer : 50000, eps : 4.2%\n",
            "n_episode :780, score : 205.8, n_buffer : 50000, eps : 4.1%\n",
            "n_episode :800, score : 218.4, n_buffer : 50000, eps : 4.0%\n",
            "n_episode :820, score : 158.3, n_buffer : 50000, eps : 3.9%\n",
            "n_episode :840, score : 195.1, n_buffer : 50000, eps : 3.8%\n",
            "n_episode :860, score : 151.7, n_buffer : 50000, eps : 3.7%\n",
            "n_episode :880, score : 300.7, n_buffer : 50000, eps : 3.6%\n",
            "n_episode :900, score : 239.9, n_buffer : 50000, eps : 3.5%\n",
            "n_episode :920, score : 311.6, n_buffer : 50000, eps : 3.4%\n",
            "n_episode :940, score : 261.4, n_buffer : 50000, eps : 3.3%\n",
            "n_episode :960, score : 206.6, n_buffer : 50000, eps : 3.2%\n",
            "n_episode :980, score : 277.1, n_buffer : 50000, eps : 3.1%\n",
            "n_episode :1000, score : 226.4, n_buffer : 50000, eps : 3.0%\n",
            "n_episode :1020, score : 219.6, n_buffer : 50000, eps : 2.9%\n",
            "n_episode :1040, score : 157.8, n_buffer : 50000, eps : 2.8%\n",
            "n_episode :1060, score : 167.8, n_buffer : 50000, eps : 2.7%\n",
            "n_episode :1080, score : 178.2, n_buffer : 50000, eps : 2.6%\n",
            "n_episode :1100, score : 189.8, n_buffer : 50000, eps : 2.5%\n",
            "n_episode :1120, score : 179.8, n_buffer : 50000, eps : 2.4%\n",
            "n_episode :1140, score : 187.2, n_buffer : 50000, eps : 2.3%\n",
            "n_episode :1160, score : 168.6, n_buffer : 50000, eps : 2.2%\n",
            "n_episode :1180, score : 188.6, n_buffer : 50000, eps : 2.1%\n",
            "n_episode :1200, score : 152.2, n_buffer : 50000, eps : 2.0%\n",
            "n_episode :1220, score : 157.2, n_buffer : 50000, eps : 1.9%\n",
            "n_episode :1240, score : 118.0, n_buffer : 50000, eps : 1.8%\n",
            "n_episode :1260, score : 159.4, n_buffer : 50000, eps : 1.7%\n",
            "n_episode :1280, score : 219.8, n_buffer : 50000, eps : 1.6%\n",
            "n_episode :1300, score : 140.3, n_buffer : 50000, eps : 1.5%\n",
            "n_episode :1320, score : 202.2, n_buffer : 50000, eps : 1.4%\n",
            "n_episode :1340, score : 167.2, n_buffer : 50000, eps : 1.3%\n",
            "n_episode :1360, score : 186.6, n_buffer : 50000, eps : 1.2%\n",
            "n_episode :1380, score : 169.6, n_buffer : 50000, eps : 1.1%\n",
            "n_episode :1400, score : 102.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1420, score : 166.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1440, score : 148.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1460, score : 163.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1480, score : 175.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1500, score : 162.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1520, score : 173.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1540, score : 186.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1560, score : 193.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1580, score : 249.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1600, score : 223.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1620, score : 220.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1640, score : 186.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1660, score : 254.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1680, score : 248.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1700, score : 219.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1720, score : 169.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1740, score : 281.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1760, score : 209.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1780, score : 209.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1800, score : 177.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1820, score : 211.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1840, score : 168.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1860, score : 152.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1880, score : 207.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1900, score : 227.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1920, score : 218.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1940, score : 197.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1960, score : 210.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :1980, score : 206.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2000, score : 211.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2020, score : 202.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2040, score : 173.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2060, score : 199.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2080, score : 259.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2100, score : 301.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2120, score : 214.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2140, score : 224.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2160, score : 279.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2180, score : 33.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2200, score : 115.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2220, score : 225.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2240, score : 115.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2260, score : 284.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2280, score : 413.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2300, score : 279.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2320, score : 161.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2340, score : 149.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2360, score : 234.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2380, score : 264.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2400, score : 308.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2420, score : 361.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2440, score : 411.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2460, score : 400.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2480, score : 365.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2500, score : 253.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2520, score : 328.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2540, score : 266.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2560, score : 269.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2580, score : 318.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2600, score : 268.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2620, score : 391.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2640, score : 353.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2660, score : 377.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2680, score : 363.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2700, score : 352.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2720, score : 424.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2740, score : 478.2, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2760, score : 409.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2780, score : 357.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2800, score : 420.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2820, score : 238.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2840, score : 341.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2860, score : 284.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2880, score : 325.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2900, score : 268.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2920, score : 344.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2940, score : 280.5, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2960, score : 283.9, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :2980, score : 233.8, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3000, score : 288.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3020, score : 387.4, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3040, score : 315.0, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3060, score : 258.1, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3080, score : 404.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3100, score : 313.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3120, score : 140.3, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3140, score : 227.6, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3160, score : 183.7, n_buffer : 50000, eps : 1.0%\n",
            "n_episode :3180, score : 178.6, n_buffer : 50000, eps : 1.0%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-871dc58d492f>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-871dc58d492f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-871dc58d492f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(q, q_target, memory, optimizer)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH9 Actor Critic"
      ],
      "metadata": {
        "id": "0hj7_8h9lwhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0002\n",
        "gamma         = 0.98\n",
        "n_rollout     = 10\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.data = []\n",
        "\n",
        "        self.fc1 = nn.Linear(4,256)\n",
        "        self.fc_pi = nn.Linear(256,2)\n",
        "        self.fc_v = nn.Linear(256,1)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def pi(self, x, softmax_dim = 0):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc_pi(x)\n",
        "        prob = F.softmax(x, dim=softmax_dim)\n",
        "        return prob\n",
        "\n",
        "    def v(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        v = self.fc_v(x)\n",
        "        return v\n",
        "\n",
        "    def put_data(self, transition):\n",
        "        self.data.append(transition)\n",
        "\n",
        "    def make_batch(self):\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
        "        for transition in self.data:\n",
        "            s,a,r,s_prime,done = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r/100.0])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask = 0.0 if done else 1.0\n",
        "            done_lst.append([done_mask])\n",
        "\n",
        "        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "                                                               torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "                                                               torch.tensor(done_lst, dtype=torch.float)\n",
        "        self.data = []\n",
        "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n",
        "\n",
        "    def train_net(self):\n",
        "        s, a, r, s_prime, done = self.make_batch()\n",
        "        td_target = r + gamma * self.v(s_prime) * done\n",
        "        delta = td_target - self.v(s)\n",
        "\n",
        "        pi = self.pi(s, softmax_dim=1)\n",
        "        pi_a = pi.gather(1,a)\n",
        "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(self.v(s), td_target.detach())\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    model = ActorCritic()\n",
        "    print_interval = 20\n",
        "    score = 0.0\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        done = False\n",
        "        s = env.reset()\n",
        "        while not done:\n",
        "            for t in range(n_rollout):\n",
        "                prob = model.pi(torch.from_numpy(s).float())\n",
        "                m = Categorical(prob)\n",
        "                a = m.sample().item()\n",
        "                s_prime, r, done, info = env.step(a)\n",
        "                model.put_data((s,a,r,s_prime,done))\n",
        "\n",
        "                s = s_prime\n",
        "                score += r\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            model.train_net()\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\n",
        "            score = 0.0\n",
        "    env.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "-HuUZl51okfX",
        "outputId": "6cdcf29d-482e-4ab9-a802-4db2778ae220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of episode :20, avg score : 21.4\n",
            "# of episode :40, avg score : 23.8\n",
            "# of episode :60, avg score : 25.0\n",
            "# of episode :80, avg score : 24.2\n",
            "# of episode :100, avg score : 22.6\n",
            "# of episode :120, avg score : 27.1\n",
            "# of episode :140, avg score : 28.9\n",
            "# of episode :160, avg score : 28.2\n",
            "# of episode :180, avg score : 29.8\n",
            "# of episode :200, avg score : 32.3\n",
            "# of episode :220, avg score : 37.8\n",
            "# of episode :240, avg score : 40.8\n",
            "# of episode :260, avg score : 46.6\n",
            "# of episode :280, avg score : 56.5\n",
            "# of episode :300, avg score : 46.5\n",
            "# of episode :320, avg score : 53.2\n",
            "# of episode :340, avg score : 57.0\n",
            "# of episode :360, avg score : 70.9\n",
            "# of episode :380, avg score : 65.7\n",
            "# of episode :400, avg score : 69.6\n",
            "# of episode :420, avg score : 74.2\n",
            "# of episode :440, avg score : 77.8\n",
            "# of episode :460, avg score : 86.3\n",
            "# of episode :480, avg score : 94.6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-efc71599e668>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-efc71599e668>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0ms_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         )\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/constraints.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CH9 Reinforce"
      ],
      "metadata": {
        "id": "0zfWCdqwomoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0002\n",
        "gamma         = 0.98\n",
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Policy, self).__init__()\n",
        "        self.data = []\n",
        "\n",
        "        self.fc1 = nn.Linear(4, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x), dim=0)\n",
        "        return x\n",
        "\n",
        "    def put_data(self, item):\n",
        "        self.data.append(item)\n",
        "\n",
        "    def train_net(self):\n",
        "        R = 0\n",
        "        self.optimizer.zero_grad()\n",
        "        for r, prob in self.data[::-1]:\n",
        "            R = r + gamma * R\n",
        "            loss = -torch.log(prob) * R\n",
        "            loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.data = []\n",
        "\n",
        "def main():\n",
        "    env = gym.make('CartPole-v1')\n",
        "    pi = Policy()\n",
        "    score = 0.0\n",
        "    print_interval = 20\n",
        "\n",
        "    for n_epi in range(10000):\n",
        "        s = env.reset()\n",
        "        done = False\n",
        "\n",
        "        while not done: # CartPole-v1 forced to terminates at 500 step.\n",
        "            prob = pi(torch.from_numpy(s).float())\n",
        "            m = Categorical(prob)\n",
        "            a = m.sample()\n",
        "            s_prime, r, done, info = env.step(a.item())\n",
        "            pi.put_data((r,prob[a]))\n",
        "            s = s_prime\n",
        "            score += r\n",
        "\n",
        "        pi.train_net()\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            print(\"# of episode :{}, avg score : {}\".format(n_epi, score/print_interval))\n",
        "            score = 0.0\n",
        "    env.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "VjeYxMsuoo9C",
        "outputId": "9868cd05-a576-436f-a183-2b6da200d79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of episode :20, avg score : 20.55\n",
            "# of episode :40, avg score : 17.6\n",
            "# of episode :60, avg score : 18.1\n",
            "# of episode :80, avg score : 20.3\n",
            "# of episode :100, avg score : 21.9\n",
            "# of episode :120, avg score : 20.45\n",
            "# of episode :140, avg score : 24.95\n",
            "# of episode :160, avg score : 18.45\n",
            "# of episode :180, avg score : 19.4\n",
            "# of episode :200, avg score : 28.8\n",
            "# of episode :220, avg score : 27.15\n",
            "# of episode :240, avg score : 24.6\n",
            "# of episode :260, avg score : 36.3\n",
            "# of episode :280, avg score : 26.55\n",
            "# of episode :300, avg score : 29.45\n",
            "# of episode :320, avg score : 28.2\n",
            "# of episode :340, avg score : 27.75\n",
            "# of episode :360, avg score : 44.55\n",
            "# of episode :380, avg score : 30.65\n",
            "# of episode :400, avg score : 44.45\n",
            "# of episode :420, avg score : 43.25\n",
            "# of episode :440, avg score : 39.45\n",
            "# of episode :460, avg score : 41.1\n",
            "# of episode :480, avg score : 35.9\n",
            "# of episode :500, avg score : 47.85\n",
            "# of episode :520, avg score : 49.65\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9d829c9a6ae8>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9d829c9a6ae8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_epi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-9d829c9a6ae8>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubmPPsI1pUzt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}